[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uma Abordagem Assintótica aos Testes de Hipótese",
    "section": "",
    "text": "Testes Assintóticos\nUm dos objetivos da inferência estatística consiste em fazer deduções acerca do modelo estatístico gerador dos dados observados, o que geralmente é feito, no caso paramétrico, com respeito a uma quantidade θ (podendo ser um escalar ou um vetor). Além da fase relacionada a estimativas pontuais e intervalares, frequentemente, tal interesse baseia-se em avaliar o quão plausível é a hipótese de que o parâmetro θ pertença a um determinado subconjunto do espaço paramétrico (conjunto de todos os valores possíveis para θ). Esse procedimento é uma das vertentes da inferência estatística, e é chamado de teste de hipóteses. Na literatura, existem algumas propostas de métodos para se testar hipóteses, como por exemplo, o lema de Neyman-Pearson que nos fornece testes com propriedades ótimas. Contudo, o uso desses testes nem sempre é possível. Dificuldades relacionadas com o modelo adotado, ou com as hipóteses consideradas complexas ou até mesmo com a álgebra das estatísticas do teste tornam esse processo bastante trabalhoso. Uma opção muito conhecida e propagada é uso de testes assintóticos. Entre os testes assintóticos, destacam-se três, sendo, esses: Teste da Razão de Verossimilhanças generalizado, Teste de Wald e o Teste Score. Em casos regulares, essas três estatísticas são assintoticamente equivalentes sob a hipótese nula, onde seguem uma distribuição \\(X^2_1\\). (Filho and Montalvo 2019)\nNeste trabalho, com intuito de comparar a eficácia dos testes assintóticos, foi realizado uma exposição teórica do assunto e estudos de simulação em que foram avaliados a taxa de rejeição e poder empírico sob tamanho de amostras diferentes.\nPara isso foi escolhida a distribuição \\(Beta(\\alpha,1)\\), e o seguinte vetor de tamanhos amostrais \\((n=10, 50, 100, 500, 1000, 5000, 10000)\\)\n\n\n\n\nFilho, Daniel Jacinto dos Santos, and Gualberto Gualberto Montalvo. 2019. “Portal de Periódicos Da UFC.” Portal de Periódicos Da UFC. http://periodicos.ufc.br/."
  },
  {
    "objectID": "intro.html#f.d.p-e-aplicações",
    "href": "intro.html#f.d.p-e-aplicações",
    "title": "1  Distribuição Beta",
    "section": "1.1 F.D.P e aplicações",
    "text": "1.1 F.D.P e aplicações\nEm teoria da probabilidade e estatística, a distribuição beta é uma família de distribuições de probabilidade contínuas definidas no intervalo \\([0,1]\\) parametrizado por dois parâmetros positivos, denotados por \\(\\alpha\\) e \\(\\beta\\), que aparecem como expoentes da variável aleatória e controlam o formato da distribuição.\nA distribuição beta tem sido aplicada para modelar o comportamento de variáveis aleatórias limitadas a intervalos de tamanho finito em uma grande quantidade de disciplinas.\nEm Inferência bayesiana, a distribuição beta é a distribuição conjugada a priori da distribuição de Bernoulli, distribuição binomial, distribuição binomial negativa e distribuição geométrica. Por exemplo, a distribuição beta pode ser usada na análise bayesiana para descrever conhecimentos iniciais sobre a probabilidade de sucesso assim como a probabilidade de que um veículo espacial vai completar uma missão especificada. A distribuição beta é um modelo conveniente para comportamento aleatório de porcentagens e proporções. (Johnson, Kotz, and Balakrishnan 1995)\nSua Função Densidade de Probabilidade é dado por: \\[f(x|\\alpha,\\beta)=\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\] O estudo desenvolvido nesse livro buscou estudar apenas distribuições uniparamétricas, assim, o parametro \\(\\beta\\) foi fixado no valor de \\(1\\) para o calculo do E.M.V e Informação de Fisher e tambem para as simulações computacionais. Assim, a F.D.P de uma Distribuição \\(Beta(\\alpha,1)\\) é dada por: \\[f(x|\\alpha)=\\alpha\\ x^{\\alpha-1}\\]\nPara o desenvolvimento dos testes, é necessário o calculo do E.M.V e Informação de Fisher. Nos tópicos a seguir, tais calculos foram feitos e demonstrados"
  },
  {
    "objectID": "intro.html#estimador-de-máxima-verossimilhança",
    "href": "intro.html#estimador-de-máxima-verossimilhança",
    "title": "1  Distribuição Beta",
    "section": "1.2 Estimador de Máxima Verossimilhança",
    "text": "1.2 Estimador de Máxima Verossimilhança\nA Estimador de Máxima Verossimilhança (EMV) é um método de estimar os parâmetros de uma distribuição de probabilidade assumida, dados alguns dados observados. Isso é obtido maximizando uma função de verossimilhança de modo que, sob o modelo estatístico assumido, os dados observados sejam os mais prováveis. O ponto no espaço de parâmetros que maximiza a função de verossimilhança é chamado de estimativa de verossimilhança máxima. A lógica da máxima verossimilhança é intuitiva e flexível e, como tal, o método tornou-se um meio dominante de inferência estatística (Rossi 2018)\nDado uma distribuição \\(Beta(\\alpha,1)=\\alpha\\ x^{\\alpha-1}\\), tem-se a seguinte função de Verossimilhança:\n\\[L(\\alpha|\\tilde{x})=\\alpha^n \\prod{x_i^{\\alpha-1}}\\] Para facilitar sua maxização, utilizou-se \\(log(L(\\alpha|\\tilde{x}))=l(\\alpha|\\tilde{x})\\), dado por:\n\\[l(\\alpha,|\\tilde x)=nlog(\\alpha)+\\sum(\\alpha-1)\\ log(x_i)\\]\nMaximando a função:\n\\[\\frac{dl}{d\\alpha}=\\frac{n}{\\alpha}+\\sum log(x_i)\\]\nPortanto: \\[\\hat{\\alpha}=\\frac{-n}{\\sum log(x_i)}\\]"
  },
  {
    "objectID": "intro.html#informação-de-fisher",
    "href": "intro.html#informação-de-fisher",
    "title": "1  Distribuição Beta",
    "section": "1.3 Informação de Fisher",
    "text": "1.3 Informação de Fisher\nA Informação de Fisher é uma forma de medir a quantidade de informação que uma variável aleatória observável X carrega sobre um parâmetro desconhecido θ de uma distribuição que modela X. Formalmente, é a variância da pontuação, ou o valor esperado da informação observada. (Ly et al. 2017)\nÉ dada por: \\(E((\\frac{dl}{d\\theta})^2)\\) ou \\(-E(\\frac{d^2l}{d\\theta^2})\\) nos casos em que as condições de regularidade são satisfeitas\nA Informação de Fisher da distribuição \\(Beta(\\alpha,1)\\) é dada por:\n\\[\\frac{dl}{d\\alpha}=\\frac{n}{\\alpha}+\\sum log(x_i)\\]\n\\[\\frac{d^2l}{d\\alpha^2}=-\\frac{n}{\\alpha^2}\\] \\[-E(-\\frac{n}{\\alpha^2})=\\frac{n}{\\alpha^2}\\]\n\n\n\n\nJohnson, Norman L, Samuel Kotz, and Narayanaswamy Balakrishnan. 1995. Continuous Univariate Distributions, Volume 2. Vol. 289. John wiley & sons.\n\n\nLy, Alexander, Maarten Marsman, Josine Verhagen, Raoul PPP Grasman, and Eric-Jan Wagenmakers. 2017. “A Tutorial on Fisher Information.” Journal of Mathematical Psychology 80: 40–55.\n\n\nRossi, Richard J. 2018. Mathematical Statistics: An Introduction to Likelihood Based Inference. John Wiley & Sons."
  },
  {
    "objectID": "summary.html#hipóteses-testadas",
    "href": "summary.html#hipóteses-testadas",
    "title": "2  Simulação Computacional dos testes",
    "section": "2.1 Hipóteses Testadas",
    "text": "2.1 Hipóteses Testadas\nPara o desenvolvimento dos testes, é necessário fixar um valor para \\(\\alpha\\). Assim, foi fixado o valor \\(\\alpha=5\\), onde testou-se as hipóteses:\n\\[\\label{eq:t}\n  \\begin{aligned}\n    H_0: \\alpha = 5 \\\\        \n    H_1: \\alpha \\ != 5\n  \\end{aligned}\\]"
  },
  {
    "objectID": "summary.html#declaração-das-funções",
    "href": "summary.html#declaração-das-funções",
    "title": "2  Simulação Computacional dos testes",
    "section": "2.2 Declaração das funções",
    "text": "2.2 Declaração das funções\nCom base nos calculos do E.M.V e da Informação de Fisher, foram desenvolvidas funções para serem utilizadas posteriormente no desenvolvimento de cada teste\n\n\n\n\nbeta_llhd_function=function(data,alpha){\n  n_size=length(data)\n  \n  out_sum=n_size*log(alpha)\n  in_sum=(alpha-1)*log(data)%>%\n          sum()\n  \n  joint=out_sum+in_sum\n  \n  return(joint)\n}\n\n\nbeta_shape1_mle=function(data){\n  n_size=length(data)\n  numerator=-n_size\n  denominator=log(data)%>%\n                sum()\n  \n  return(numerator/denominator)\n}"
  },
  {
    "objectID": "summary.html#e.m.v-para-diferentes-tamanhos-amostrais",
    "href": "summary.html#e.m.v-para-diferentes-tamanhos-amostrais",
    "title": "2  Simulação Computacional dos testes",
    "section": "2.3 E.M.V para diferentes tamanhos amostrais",
    "text": "2.3 E.M.V para diferentes tamanhos amostrais\nDurante a avaliação de cada teste, diferentes tamanhos amostrais foram utilizados e portanto calculou-se o Estimativa de Máxima Verossimilhança para cada tamanho.\nA tabela a seguir apresenta o estimativa para cada tamanho, e sua diferença ao quadrado em relação ao \\(\\alpha=5\\) fixado\n\nalpha=5\n\n\nn_size_vector=c(10, 50, 100, 500, 1000, 5000, 10000)\n\n\nmles=sapply(seq_along(n_size_vector),function(i){\n    replicate(5000,rbeta(n=n_size_vector[i],shape1 = 5,shape2 = 1))%>%\n    apply(2,beta_shape1_mle)%>%\n    mean()%>%\n    return()\n  }\n)\n\n\ndf=cbind('N_size'=n_size_vector,'MLE'=mles,'$\\ (\\\\hat{\\\\alpha}-\\\\alpha_0)^2$'=(mles-5)^2)%>%\n   as.data.frame()\n\ndf %>%\n  kbl(caption = 'Estimativa em Diferentes Tamanhos Amostrais') %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\nEstimativa em Diferentes Tamanhos Amostrais\n \n  \n    N_size \n    MLE \n    $ (\\hat{\\alpha}-\\alpha_0)^2$ \n  \n \n\n  \n    10 \n    5.550016 \n    0.3025172 \n  \n  \n    50 \n    5.107608 \n    0.0115795 \n  \n  \n    100 \n    5.053797 \n    0.0028941 \n  \n  \n    500 \n    5.015988 \n    0.0002556 \n  \n  \n    1000 \n    5.005372 \n    0.0000289 \n  \n  \n    5000 \n    5.000470 \n    0.0000002 \n  \n  \n    10000 \n    5.002283 \n    0.0000052 \n  \n\n\n\n\n\nÉ possivel notar que para um tamanho amostral baixo, foi obtida uma boa aproximação, e ao aumentar o tamanho amostral, o erro converge a \\(0\\)"
  },
  {
    "objectID": "lhood.html#conceito-e-forma-teórica",
    "href": "lhood.html#conceito-e-forma-teórica",
    "title": "3  Teste da Razão de Verossimilhança",
    "section": "3.1 Conceito e forma teórica",
    "text": "3.1 Conceito e forma teórica\nO teste de razão de verossimilhança avalia a qualidade do ajuste de dois modelos estatísticos concorrentes com base na razão de suas verossimilhanças, especificamente um encontrado por maximização em todo o espaço de parâmetros e outro encontrado após a imposição de alguma restrição. Se a restrição (ou seja, a hipótese nula) for suportada pelos dados observados, as duas probabilidades não devem diferir em mais do que o erro de amostragem. Assim, o teste da razão de verossimilhança testa se essa razão é significativamente diferente de um ou, de forma equivalente, se seu logaritmo natural é significativamente diferente de zero. (King 1989)\nA estatística de teste é dada por:\n\\[2[l(\\hat\\theta)-l(\\theta_0)]\\sim_{n\\to\\infty}X^2_1\\] Onde, no caso do modelo \\(Beta(\\alpha,1)\\), a estatística do teste possui a seguinte forma:\n\\[2[(nlog(\\hat\\alpha)+\\sum(\\hat\\alpha-1)\\ log(x_i))-(nlog(\\alpha_0)+\\sum(\\alpha_0-1)\\ log(x_i)]\\]"
  },
  {
    "objectID": "lhood.html#avaliação-computacional",
    "href": "lhood.html#avaliação-computacional",
    "title": "3  Teste da Razão de Verossimilhança",
    "section": "3.2 Avaliação Computacional",
    "text": "3.2 Avaliação Computacional\n\n\n\n\n\n\n\nn_size_vector=c(10, 50, 100, 500, 1000, 5000, 10000)\nalpha=5\nalpha_vector=seq(2,8,by=0.2)\n\n\nllhood_ratio_test=function(data,H_0){\n  alpha_hat=beta_shape1_mle(data)\n  ll_alpha_hat=beta_llhd_function(data,alpha_hat)\n  \n  ll_alpha_0=beta_llhd_function(data,H_0)\n  \n  llhood_value=2*(ll_alpha_hat-ll_alpha_0)\n  return(llhood_value)\n}\n\n\n3.2.1 Poder do teste\n\npower_decision=function(x){\n  return(ifelse(x>qchisq(0.975,1) | x<qchisq(0.025,1) ,1,0))\n}\n\nllhood_ratio_test=function(data,H_0){\n  alpha_hat=beta_shape1_mle(data)\n  ll_alpha_hat=beta_llhd_function(data,alpha_hat)\n  \n  ll_alpha_0=beta_llhd_function(data,H_0)\n  \n  llhood_value=2*(ll_alpha_hat-ll_alpha_0)\n  return(llhood_value)\n}\n\n\nllhood_power=sapply(seq_along(n_size_vector),function(i){\n  llhood_power_step=sapply(seq_along(alpha_vector),function(k){replicate(600,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,llhood_ratio_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/600}\n)\n  return(llhood_power_step)\n\n})\n\n\ntbl_llhood_power=as_tibble(llhood_power)%>%\n                 rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_llhood_power_step=tbl_llhood_power%>%\n  pivot_longer(cols = everything())\n\n\n\n\nindex=sapply(seq_along(alpha_vector),function(i){\n      rep(alpha_vector[i],7)\n      })%>%\n      as_tibble()%>%\n      pivot_longer(cols = everything())%>%\n      arrange(value)\n\npivot_llhood_power=cbind(pivot_llhood_power_step,index$value)%>%\n                    rename('index'='index$value')\n  \n\nggplot(pivot_llhood_power, aes(x=index, y=value)) +\n  geom_line(linetype=1,linewidth=1.05,color='#FC9B5C')+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\nAo observar os gráficos, é possivel notar em quais tamanhos amostrais a função poder apresenta uma aparência desejável. Em um tamanho amostral menor que 500, nota-se que o teste apresenta uma alta probabilidade do Erro do Tipo II, ou seja, não rejeitar \\(H_0\\) quando \\(H_0\\) é falsa, mesmo quando o \\(\\alpha_0\\) testado está distante do \\(\\alpha\\) verdadeiro. Em um tamanho amostral igual ou superior a 500, a função passa a apresentar um comportamento melhor, onde a probabilidade de se rejeitar \\(H_0\\), com \\(H_0\\) falsa, vai para 1 e converge para o nivel de significancia de \\(5\\%\\) ao se aproximar do \\(\\alpha_0\\) verdadeiro. Para o tamanho amostral \\(10.000\\) é observado uma melhor precisão\nA tabela a seguir apresenta detalhadamente a taxa de rejeição para cada tamanho amostral em \\(\\tilde\\alpha=(2,2.2,2.4,2.6,...8)\\)\n\ndf_alpha=data.frame(alpha=c(2,3,4,4.6,4.8,5,5.2,5.4,6,7,8))\ndf_power_llhood_print=tbl_llhood_power[c(1,6,11,14,15,16,17,18,21,26,31),]\n    \ndf=cbind(alpha=df_alpha,round(df_power_llhood_print,3))%>%\n  rename('$\\\\alpha$'=alpha)\n\n\ndf %>%\n  kbl(caption = 'Poder em Diferentes Tamanhos Amostrais, $\\\\alpha$ verdadeiro = 5') %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\nPoder em Diferentes Tamanhos Amostrais, $\\alpha$ verdadeiro = 5\n \n  \n    $\\alpha$ \n    N_10 \n    N_50 \n    N_100 \n    N_500 \n    N_1000 \n    N_5000 \n    N_10000 \n  \n \n\n  \n    2.0 \n    0.778 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    3.0 \n    0.330 \n    0.923 \n    0.997 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.0 \n    0.090 \n    0.290 \n    0.528 \n    0.997 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.6 \n    0.057 \n    0.088 \n    0.097 \n    0.363 \n    0.603 \n    1.000 \n    1.000 \n  \n  \n    4.8 \n    0.058 \n    0.057 \n    0.068 \n    0.103 \n    0.202 \n    0.763 \n    0.963 \n  \n  \n    5.0 \n    0.043 \n    0.055 \n    0.055 \n    0.043 \n    0.055 \n    0.057 \n    0.057 \n  \n  \n    5.2 \n    0.055 \n    0.060 \n    0.057 \n    0.098 \n    0.165 \n    0.718 \n    0.952 \n  \n  \n    5.4 \n    0.040 \n    0.082 \n    0.113 \n    0.298 \n    0.605 \n    1.000 \n    1.000 \n  \n  \n    6.0 \n    0.075 \n    0.192 \n    0.332 \n    0.975 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    7.0 \n    0.127 \n    0.522 \n    0.848 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    8.0 \n    0.173 \n    0.840 \n    0.998 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\n\n\n3.2.2 Distribuição Qui-Quadrado assintótica\n\nchi_genarate_llhood=sapply(seq_along(n_size_vector),function(i){\n    gen_samples=replicate(3000,rbeta(n=n_size_vector[i],shape1 = 2,shape2 = 1))\n    apply(gen_samples, 2, llhood_ratio_test,2)%>%\n      return()\n  }\n)\n\ntbl_chi_genarate_llhood=as_tibble(chi_genarate_llhood)%>%\n  rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_chi_genarate_llhood=tbl_chi_genarate_llhood%>%\n  pivot_longer(cols = everything())\n\n\n\n\npivot_chi_genarate_llhood%>% \n  ggplot(aes(x = value)) + \n  geom_histogram(aes(y =after_stat(density)),color='black',fill='#FC9B5C')+\n  stat_function(fun = dchisq, args = list(df=1),color='#FA9BEB')+ \n  ylim(c(0,1))+\n  xlim(c(0,10))+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\n\npivot_chi_genarate_llhood%>% \n  ggplot(aes(x = value)) + \n  stat_ecdf(geom = \"step\",color='#FC9B5C')+\n  stat_function(fun = pchisq, args = list(df=1),color='#FA9BEB')+ \n  facet_wrap(~name)+\n  ylim(c(0.92,1))+\n  theme_dark()\n\n\n\n\n\n  k=sapply(seq_along(n_size_vector),function(i){\n     ks.test(chi_genarate_llhood[,i],'pchisq',1)$p.value\n  })\n\n\n  \ndf=data.frame(N_size=n_size_vector,p.value=k)\n\ndf %>%\n  kbl() %>%\n  kable_paper(\"hover\", full_width = F)\n\n\n\n \n  \n    N_size \n    p.value \n  \n \n\n  \n    10 \n    0.0659501 \n  \n  \n    50 \n    0.0666171 \n  \n  \n    100 \n    0.0473478 \n  \n  \n    500 \n    0.9616854 \n  \n  \n    1000 \n    0.1867074 \n  \n  \n    5000 \n    0.7515236 \n  \n  \n    10000 \n    0.1863548 \n  \n\n\n\n\n\n\n\n\n\nKing, Gary. 1989. Unifying Political Methodology: The Likelihood Theory of Statistical Inference. Cambridge University Press."
  },
  {
    "objectID": "wald.html#conceito-e-forma-teórica",
    "href": "wald.html#conceito-e-forma-teórica",
    "title": "4  Teste Wald",
    "section": "4.1 Conceito e forma teórica",
    "text": "4.1 Conceito e forma teórica\nO teste avalia restrições em parâmetros estatísticos com base na distância ponderada entre a estimativa irrestrita e seu valor hipotético sob a hipótese nula, onde o peso é a precisão da estimativa. Intuitivamente, quanto maior essa distância ponderada, menos provável é que a restrição seja verdadeira. Embora as distribuições de amostras finitas dos testes de Wald sejam geralmente desconhecidas, ele tem uma distribuição \\(X^2\\) assintótica sob a hipótese nula, um fato que pode ser usado para determinar a significância estatística. (Ward and Ahlquist 2018)\nA estatística de teste é dada por:\n\\[\\frac{\\sqrt{n}(\\hat\\theta-\\theta_0)}{\\sqrt{I_f(\\theta)^{-1}}}\\sim_{n\\to\\infty} X^2_1\\]\nOnde, no caso do modelo \\(Beta(\\alpha,1)\\), a estatística do teste possui a seguinte forma:\n\\[\\frac{\\sqrt{n}(\\hat\\alpha-\\alpha_0)}{\\sqrt{\\frac{\\hat\\alpha^2}{n}}}\\]"
  },
  {
    "objectID": "wald.html#avaliação-computacional",
    "href": "wald.html#avaliação-computacional",
    "title": "4  Teste Wald",
    "section": "4.2 Avaliação Computacional",
    "text": "4.2 Avaliação Computacional\n\n\n\n\n\n\n\nn_size_vector=c(10, 50, 100, 500, 1000, 5000, 10000)\nalpha=5\nalpha_vector=seq(2,8,by=0.2)\n\n\nwald_test=function(data,H_0){\n  alpha_hat=beta_shape1_mle(data)\n  fisher_information=1/(alpha_hat^2)\n  \n  w_value=(((alpha_hat-H_0)*sqrt(length(data)))/sqrt(1/fisher_information))^2\n  \n  return(w_value)\n}\n\n\n4.2.1 Poder do teste\n\npower_decision=function(x){\n  return(ifelse(x>qchisq(0.975,1) | x<qchisq(0.025,1) ,1,0))\n}\n\nwald_power=sapply(seq_along(n_size_vector),function(i){\n  wald_power_step=sapply(seq_along(alpha_vector),function(k){replicate(600,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,wald_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/600}\n)\n  return(wald_power_step)\n\n})\n\ntbl_wald_power=as_tibble(wald_power)%>%\n                 rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_wald_power_step=tbl_wald_power%>%\n  pivot_longer(cols = everything())\n\n\n\n\nindex=sapply(seq_along(alpha_vector),function(i){\n      rep(alpha_vector[i],7)\n      })%>%\n      as_tibble()%>%\n      pivot_longer(cols = everything())%>%\n      arrange(value)\n\npivot_wald_power=cbind(pivot_wald_power_step,index$value)%>%\n                    rename('index'='index$value')\n  \n\nggplot(pivot_wald_power, aes(x=index, y=value)) +\n  geom_line(linetype=1,linewidth=1.05,color='#FC9B5C')+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\nAo observar os gráficos, é possivel notar em quais tamanhos amostrais a função poder apresenta uma aparência desejável. Em um tamanho amostral menor que 500, nota-se que o teste apresenta uma alta probabilidade do Erro do Tipo II, ou seja, não rejeitar \\(H_0\\) quando \\(H_0\\) é falsa, mesmo quando o \\(\\alpha_0\\) testado está distante do \\(\\alpha\\) verdadeiro. Em um tamanho amostral igual ou superior a 500, a função passa a apresentar um comportamento melhor, onde a probabilidade de se rejeitar \\(H_0\\), com \\(H_0\\) falsa, vai para 1 e converge para o nivel de significancia de \\(5\\%\\) ao se aproximar do \\(\\alpha_0\\) verdadeiro. Para o tamanho amostral \\(10.000\\) é observado uma melhor precisão\nA tabela a seguir apresenta detalhadamente a taxa de rejeição para cada tamanho amostral em \\(\\tilde\\alpha=(2,2.2,2.4,2.6,...8)\\)\n\ndf_alpha=data.frame(alpha=c(2,3,4,4.6,4.8,5,5.2,5.4,6,7,8))\ndf_power_wald_print=tbl_wald_power[c(1,6,11,14,15,16,17,18,21,26,31),]\n    \ndf=cbind(alpha=df_alpha,round(df_power_wald_print,3))%>%\n  rename('$\\\\alpha$'=alpha)\n\n\ndf %>%\n  kbl(caption = 'Poder em Diferentes Tamanhos Amostrais, $\\\\alpha$ verdadeiro = 5') %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\nPoder em Diferentes Tamanhos Amostrais, $\\alpha$ verdadeiro = 5\n \n  \n    $\\alpha$ \n    N_10 \n    N_50 \n    N_100 \n    N_500 \n    N_1000 \n    N_5000 \n    N_10000 \n  \n \n\n  \n    2.0 \n    0.862 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    3.0 \n    0.453 \n    0.938 \n    0.997 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.0 \n    0.130 \n    0.333 \n    0.577 \n    0.997 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.6 \n    0.070 \n    0.098 \n    0.130 \n    0.397 \n    0.683 \n    1.000 \n    1.000 \n  \n  \n    4.8 \n    0.057 \n    0.088 \n    0.073 \n    0.085 \n    0.173 \n    0.757 \n    0.962 \n  \n  \n    5.0 \n    0.055 \n    0.060 \n    0.048 \n    0.050 \n    0.040 \n    0.060 \n    0.033 \n  \n  \n    5.2 \n    0.033 \n    0.040 \n    0.063 \n    0.098 \n    0.155 \n    0.682 \n    0.947 \n  \n  \n    5.4 \n    0.038 \n    0.035 \n    0.073 \n    0.228 \n    0.548 \n    1.000 \n    1.000 \n  \n  \n    6.0 \n    0.032 \n    0.108 \n    0.270 \n    0.963 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    7.0 \n    0.018 \n    0.412 \n    0.807 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    8.0 \n    0.020 \n    0.717 \n    0.990 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\n\n\n4.2.2 Distribuição Qui-Quadrado assintótica\n\nchi_genarate_wald=sapply(seq_along(n_size_vector),function(i){\n    gen_samples=replicate(3000,rbeta(n=n_size_vector[i],shape1 = alpha,shape2 = 1))\n    apply(gen_samples, 2, wald_test,5)%>%\n      return()\n  }\n)\n\n\n\ntbl_chi_genarate_wald=as_tibble(chi_genarate_wald)%>%\n  rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_chi_genarate_wald=tbl_chi_genarate_wald%>%\n  pivot_longer(cols = everything())\n\n\n\n\npivot_chi_genarate_wald%>% \n  ggplot(aes(x = value)) + \n  geom_histogram(aes(y =after_stat(density)),color='black',fill='#FC9B5C')+\n  stat_function(fun = dchisq, args = list(df=1),color='#FA9BEB')+ \n  ylim(c(0,1))+\n  xlim(c(0,10))+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\n\npivot_chi_genarate_wald%>% \n  ggplot(aes(x = value)) + \n  stat_ecdf(geom = \"step\",color='#FC9B5C')+\n  stat_function(fun = pchisq, args = list(df=1),color='#FA9BEB')+ \n  facet_wrap(~name)+\n  ylim(c(0.92,1))+\n  theme_dark()\n\n\n\n\n\n  k=sapply(seq_along(n_size_vector),function(i){\n     ks.test(tbl_chi_genarate_wald[,i],'pchisq',1)$p.value\n  })\n\n\n  \ndf=data.frame(N_size=n_size_vector,p.value=k)\n\ndf %>%\n  kbl() %>%\n  kable_paper(\"hover\", full_width = F)\n\n\n\n \n  \n    N_size \n    p.value \n  \n \n\n  \n    10 \n    0.2003951 \n  \n  \n    50 \n    0.9500847 \n  \n  \n    100 \n    0.4788676 \n  \n  \n    500 \n    0.7842744 \n  \n  \n    1000 \n    0.7399528 \n  \n  \n    5000 \n    0.9532141 \n  \n  \n    10000 \n    0.3334321 \n  \n\n\n\n\n\n\n\n\n\nWard, Michael D, and John S Ahlquist. 2018. Maximum Likelihood for Social Science: Strategies for Analysis. Cambridge University Press."
  },
  {
    "objectID": "escore.html#conceito-e-forma-teórica",
    "href": "escore.html#conceito-e-forma-teórica",
    "title": "5  Teste Escore",
    "section": "5.1 Conceito e forma teórica",
    "text": "5.1 Conceito e forma teórica\nO teste de pontuação avalia restrições em parâmetros estatísticos com base no gradiente da função de verossimilhança — conhecida como pontuação — avaliada no valor do parâmetro hipotético sob a hipótese nula. Intuitivamente, se o estimador restrito estiver próximo do máximo da função de verossimilhança, a pontuação não deve diferir de zero em mais do que o erro amostral. Embora as distribuições de amostras finitas de testes de pontuação sejam geralmente desconhecidas, elas têm uma distribuição \\(X^2\\) assintótica sob a hipótese nula. (Silvey 1959)\nA estatística do teste é dada por:\n\\[\\frac{U(\\theta_0)^2}{I(\\theta_0)}\\sim_{n\\to\\infty} X^2_1\\text{ ,onde }U(\\theta_0)=\\frac{dl}{d\\theta}\\]\nNo caso do modelo \\(Beta(\\alpha,1)\\), a estatística do teste possui a seguinte forma:\n\\[\\frac{(\\frac{n}{\\alpha_0}+\\sum log(xi))^2}{\\frac{n}{\\alpha_0^2}}\\]"
  },
  {
    "objectID": "escore.html#avaliação-computacional",
    "href": "escore.html#avaliação-computacional",
    "title": "5  Teste Escore",
    "section": "5.2 Avaliação Computacional",
    "text": "5.2 Avaliação Computacional\n\n\n\n\n\n\n\nn_size_vector=c(10, 50, 100, 500, 1000, 5000, 10000)\nalpha=5\nalpha_vector=seq(2,8,by=0.2)\n\n\nscore_test=function(data,H_0){\n  n_size=length(data)\n  \n  numerator_1=(n_size/H_0)\n  numerator_2=log(data)%>%\n                sum()\n  \n  U_information=numerator_1+numerator_2\n  \n  \n  fisher_information=length(data)/(H_0^2)\n  \n  score_value=(U_information^2)/fisher_information\n  \n  \n  return(score_value)\n  \n  \n}\n\n\n5.2.1 Poder do teste\n\npower_decision=function(x){\n  return(ifelse(x>qchisq(0.975,1) | x<qchisq(0.025,1) ,1,0))\n}\n\nscore_power=sapply(seq_along(n_size_vector),function(i){\n  score_power_step=sapply(seq_along(alpha_vector),function(k){replicate(600,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,score_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/600}\n)\n  return(score_power_step)\n\n})\n\ntbl_score_power=as_tibble(score_power)%>%\n                 rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_score_power_step=tbl_score_power%>%\n  pivot_longer(cols = everything())\n\n\n\n\nindex=sapply(seq_along(alpha_vector),function(i){\n      rep(alpha_vector[i],7)\n      })%>%\n      as_tibble()%>%\n      pivot_longer(cols = everything())%>%\n      arrange(value)\n\npivot_score_power=cbind(pivot_score_power_step,index$value)%>%\n                    rename('index'='index$value')\n  \n\nggplot(pivot_score_power, aes(x=index, y=value)) +\n  geom_line(linetype=1,linewidth=1.05,color='#FC9B5C')+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\nAo observar os gráficos, é possivel notar em quais tamanhos amostrais a função poder apresenta uma aparência desejável. Em um tamanho amostral menor que 500, nota-se que o teste apresenta uma alta probabilidade do Erro do Tipo II, ou seja, não rejeitar \\(H_0\\) quando \\(H_0\\) é falsa, mesmo quando o \\(\\alpha_0\\) testado está distante do \\(\\alpha\\) verdadeiro. Em um tamanho amostral igual ou superior a 500, a função passa a apresentar um comportamento melhor, onde a probabilidade de se rejeitar \\(H_0\\), com \\(H_0\\) falsa, vai para 1 e converge para o nivel de significancia de \\(5\\%\\) ao se aproximar do \\(\\alpha_0\\) verdadeiro. Para o tamanho amostral \\(10.000\\) é observado uma melhor precisão\nA tabela a seguir apresenta detalhadamente a taxa de rejeição para cada tamanho amostral em \\(\\tilde\\alpha=(2,2.2,2.4,2.6,...8)\\)\n\ndf_alpha=data.frame(alpha=c(2,3,4,4.6,4.8,5,5.2,5.4,6,7,8))\ndf_power_score_print=tbl_score_power[c(1,6,11,14,15,16,17,18,21,26,31),]\n    \ndf=cbind(alpha=df_alpha,round(df_power_score_print,3))%>%\n  rename('$\\\\alpha$'=alpha)\n\n\ndf %>%\n  kbl(caption = 'Poder em Diferentes Tamanhos Amostrais, $\\\\alpha$ verdadeiro = 5') %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\nPoder em Diferentes Tamanhos Amostrais, $\\alpha$ verdadeiro = 5\n \n  \n    $\\alpha$ \n    N_10 \n    N_50 \n    N_100 \n    N_500 \n    N_1000 \n    N_5000 \n    N_10000 \n  \n \n\n  \n    2.0 \n    0.858 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    3.0 \n    0.450 \n    0.935 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.0 \n    0.147 \n    0.367 \n    0.558 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    4.6 \n    0.060 \n    0.098 \n    0.127 \n    0.382 \n    0.643 \n    1.000 \n    1.000 \n  \n  \n    4.8 \n    0.065 \n    0.038 \n    0.070 \n    0.135 \n    0.192 \n    0.768 \n    0.958 \n  \n  \n    5.0 \n    0.038 \n    0.040 \n    0.057 \n    0.057 \n    0.055 \n    0.055 \n    0.048 \n  \n  \n    5.2 \n    0.030 \n    0.047 \n    0.043 \n    0.085 \n    0.152 \n    0.722 \n    0.942 \n  \n  \n    5.4 \n    0.037 \n    0.042 \n    0.058 \n    0.263 \n    0.538 \n    0.998 \n    1.000 \n  \n  \n    6.0 \n    0.028 \n    0.098 \n    0.245 \n    0.958 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    7.0 \n    0.022 \n    0.400 \n    0.817 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n  \n    8.0 \n    0.018 \n    0.762 \n    0.987 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\n\n\n5.2.2 Distribuição Qui-Quadrado assintótica\n\nchi_genarate_score=sapply(seq_along(n_size_vector),function(i){\n    gen_samples=replicate(3000,rbeta(n=n_size_vector[i],shape1 = alpha,shape2 = 1))\n    apply(gen_samples, 2, score_test,5)%>%\n      return()\n  }\n)\n\n\n\ntbl_chi_genarate_score=as_tibble(chi_genarate_score)%>%\n  rename(N_10=V1,N_50=V2,N_100=V3,N_500=V4,N_1000=V5,N_5000=V6,N_10000=V7)\n\npivot_chi_genarate_score=tbl_chi_genarate_score%>%\n  pivot_longer(cols = everything())\n\n\n\n\npivot_chi_genarate_score%>% \n  ggplot(aes(x = value)) + \n  geom_histogram(aes(y =after_stat(density)),color='black',fill='#FC9B5C')+\n  stat_function(fun = dchisq, args = list(df=1),color='#FA9BEB')+ \n  ylim(c(0,1))+\n  xlim(c(0,10))+\n  facet_wrap(~name)+\n  theme_dark()\n\n\n\n\n\npivot_chi_genarate_score%>% \n  ggplot(aes(x = value)) + \n  stat_ecdf(geom = \"step\",color='#FC9B5C')+\n  stat_function(fun = pchisq, args = list(df=1),color='#FA9BEB')+ \n  facet_wrap(~name)+\n  ylim(c(0.92,1))+\n  theme_dark()\n\n\n\n\n\n  k=sapply(seq_along(n_size_vector),function(i){\n     ks.test(tbl_chi_genarate_score[,i],'pchisq',1)$p.value\n  })\n\n\n  \ndf=data.frame(N_size=n_size_vector,p.value=k)\n\ndf %>%\n  kbl() %>%\n  kable_paper(\"hover\", full_width = F)\n\n\n\n \n  \n    N_size \n    p.value \n  \n \n\n  \n    10 \n    0.0899924 \n  \n  \n    50 \n    0.9749441 \n  \n  \n    100 \n    0.1732656 \n  \n  \n    500 \n    0.7178931 \n  \n  \n    1000 \n    0.4346163 \n  \n  \n    5000 \n    0.5292972 \n  \n  \n    10000 \n    0.1371330 \n  \n\n\n\n\n\n\n\n\n\nSilvey, Samuel D. 1959. “The Lagrangian Multiplier Test.” The Annals of Mathematical Statistics 30 (2): 389–407."
  },
  {
    "objectID": "best_test.html#poder-dos-testes",
    "href": "best_test.html#poder-dos-testes",
    "title": "6  Busca pelo Melhor Teste",
    "section": "6.1 Poder dos Testes",
    "text": "6.1 Poder dos Testes\n\n\n\n\nn_size_vector=c(500,1000,5000,10000)\nalpha=5\nalpha_vector=seq(4,6,by=0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nllhood_power=sapply(seq_along(n_size_vector),function(i){\n  llhood_power_step=sapply(seq_along(alpha_vector),function(k){replicate(1000,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,llhood_ratio_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/1000}\n)\n  return(llhood_power_step)\n\n})\n\n\ntbl_llhood_power=as_tibble(llhood_power)%>%\n                 rename(N_500=V1,N_1000=V2,N_5000=V3,N_10000=V4)\n\n\nwald_power=sapply(seq_along(n_size_vector),function(i){\n  wald_power_step=sapply(seq_along(alpha_vector),function(k){replicate(1000,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,wald_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/1000}\n)\n  return(wald_power_step)\n\n})\n\n\ntbl_wald_power=as_tibble(wald_power)%>%\n                 rename(N_500=V1,N_1000=V2,N_5000=V3,N_10000=V4)\n\n\nscore_power=sapply(seq_along(n_size_vector),function(i){\n  score_power_step=sapply(seq_along(alpha_vector),function(k){replicate(1000,rbeta(n=n_size_vector[i],shape1 = alpha_vector[k],shape2 = 1))%>%\n    apply(2,score_test,alpha)%>%\n    unlist()%>%\n    sapply(power_decision)%>%\n    sum()/1000}\n)\n  return(score_power_step)\n\n})\n\n\ntbl_score_power=as_tibble(score_power)%>%\n                 rename(N_500=V1,N_1000=V2,N_5000=V3,N_10000=V4)\n\n\n\n\n\nalpha_df=data.frame(alpha=alpha_vector)\n\n\ncbind(alpha_df,round(n_500,2),round(n_1000,2),round(n_5000,2),round(n_10000,2))%>%\n  kbl(caption = \"Poder de cada Teste\") %>%\n    add_header_above(c('Vetor Alpha',\"N 500\" = 3,\"N 1000\" = 3, \"N 5000\" = 3,\"N 10000\"=3)) %>%\n    kable_classic(full_width = T)\n\n\n\nPoder de cada Teste\n \n\nVetor Alpha\nN 500\nN 1000\nN 5000\nN 10000\n\n  \n    alpha \n    Veros. \n    Wald \n    Escore \n    Veros. \n    Wald \n    Escore \n    Veros. \n    Wald \n    Escore \n    Veros. \n    Wald \n    Escore \n  \n \n\n  \n    4.0 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    4.2 \n    0.94 \n    0.95 \n    0.96 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    4.4 \n    0.72 \n    0.75 \n    0.74 \n    0.96 \n    0.96 \n    0.96 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    4.6 \n    0.38 \n    0.42 \n    0.40 \n    0.69 \n    0.66 \n    0.67 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    4.8 \n    0.10 \n    0.11 \n    0.12 \n    0.19 \n    0.19 \n    0.20 \n    0.76 \n    0.76 \n    0.75 \n    0.98 \n    0.97 \n    0.97 \n  \n  \n    5.0 \n    0.05 \n    0.05 \n    0.05 \n    0.07 \n    0.06 \n    0.04 \n    0.07 \n    0.05 \n    0.06 \n    0.05 \n    0.06 \n    0.04 \n  \n  \n    5.2 \n    0.11 \n    0.11 \n    0.09 \n    0.17 \n    0.15 \n    0.15 \n    0.72 \n    0.69 \n    0.67 \n    0.94 \n    0.96 \n    0.96 \n  \n  \n    5.4 \n    0.29 \n    0.27 \n    0.29 \n    0.56 \n    0.54 \n    0.55 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    5.6 \n    0.61 \n    0.57 \n    0.56 \n    0.91 \n    0.90 \n    0.89 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    5.8 \n    0.85 \n    0.84 \n    0.83 \n    0.99 \n    0.99 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    6.0 \n    0.96 \n    0.96 \n    0.96 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00 \n    1.00"
  },
  {
    "objectID": "best_test.html#tempo-de-execução",
    "href": "best_test.html#tempo-de-execução",
    "title": "6  Busca pelo Melhor Teste",
    "section": "6.2 Tempo de execução",
    "text": "6.2 Tempo de execução\n\n\n\n\n\n\n\n\n\n\nllhood_time=sapply(seq_along(n_size_vector),function(i){\n    summary(microbenchmark(\n        replicate(5000,rbeta(n=n_size_vector[i],shape1 = 5,shape2 = 1))%>%\n        apply(2,llhood_ratio_test,alpha)%>%\n        unlist()%>%\n        sapply(power_decision)%>%\n        sum()/5000,\n     times=100))[,4]%>%\n     return()\n\n})\n\n\nwald_time=sapply(seq_along(n_size_vector),function(i){\n    summary(microbenchmark(\n        replicate(5000,rbeta(n=n_size_vector[i],shape1 = 5,shape2 = 1))%>%\n        apply(2,wald_test,alpha)%>%\n        unlist()%>%\n        sapply(power_decision)%>%\n        sum()/5000,\n     times=100))[,4]%>%\n     return()\n\n})\n\n\nscore_time=sapply(seq_along(n_size_vector),function(i){\n    summary(microbenchmark(\n        replicate(5000,rbeta(n=n_size_vector[i],shape1 = 5,shape2 = 1))%>%\n        apply(2,score_test,alpha)%>%\n        unlist()%>%\n        sapply(power_decision)%>%\n        sum()/5000,\n     times=100))[,4]%>%\n     return()\n\n})\n\n\n\n\n\ndf_time=data.frame('N_size'=c(500,1000,5000,10000),llhood_time,wald_time,score_time)\n\ndf_time%>%\n  kbl(caption = \"Tempo de execução para cada tamanho amostral (s)\") %>%\n    kable_classic(full_width = F)\n\n\n\nTempo de execução para cada tamanho amostral (s)\n \n  \n    N_size \n    llhood_time \n    wald_time \n    score_time \n  \n \n\n  \n    500 \n    0.8190184 \n    0.6430484 \n    0.6376666 \n  \n  \n    1000 \n    1.5441608 \n    1.2007573 \n    1.1983485 \n  \n  \n    5000 \n    7.5009410 \n    5.8538932 \n    5.8058271 \n  \n  \n    10000 \n    14.7190993 \n    11.7152516 \n    11.6669150"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "Filho, Daniel Jacinto dos Santos, and Gualberto Gualberto Montalvo.\n2019. “Portal de Periódicos Da UFC.” Portal de\nPeriódicos Da UFC. http://periodicos.ufc.br/.\n\n\nJohnson, Norman L, Samuel Kotz, and Narayanaswamy Balakrishnan. 1995.\nContinuous Univariate Distributions, Volume 2. Vol. 289. John\nwiley & sons.\n\n\nKing, Gary. 1989. Unifying Political Methodology: The Likelihood\nTheory of Statistical Inference. Cambridge University Press.\n\n\nLy, Alexander, Maarten Marsman, Josine Verhagen, Raoul PPP Grasman, and\nEric-Jan Wagenmakers. 2017. “A Tutorial on Fisher\nInformation.” Journal of Mathematical Psychology 80:\n40–55.\n\n\nRossi, Richard J. 2018. Mathematical Statistics: An Introduction to\nLikelihood Based Inference. John Wiley & Sons.\n\n\nSilvey, Samuel D. 1959. “The Lagrangian Multiplier Test.”\nThe Annals of Mathematical Statistics 30 (2): 389–407.\n\n\nWard, Michael D, and John S Ahlquist. 2018. Maximum Likelihood for\nSocial Science: Strategies for Analysis. Cambridge University\nPress."
  }
]